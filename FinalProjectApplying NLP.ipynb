{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Applying NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description: \n",
    "Sentiment analysis: the sentiment of the textual data will be analyzed and classified into at least 3 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Collection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Collect a dataset of product reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Source data: https://www.kaggle.com/code/mehmetisik/rating-product-sorting-reviews-in-amazon/input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Annotate the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With labels of positive, negative or neutral sentiment, based on\n",
    "collected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled file saved at: ./data/reviews_aws/amazon_review_labeled.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>day_diff</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>total_vote</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3SBTW3WS4IQSN</td>\n",
       "      <td>B007WTAJTO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>No issues.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>1406073600</td>\n",
       "      <td>2014-07-23</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A18K1ODH1I2MVB</td>\n",
       "      <td>B007WTAJTO</td>\n",
       "      <td>0mie</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Purchased this for my device, it worked as adv...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>MOAR SPACE!!!</td>\n",
       "      <td>1382659200</td>\n",
       "      <td>2013-10-25</td>\n",
       "      <td>409</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2FII3I2MBMUIA</td>\n",
       "      <td>B007WTAJTO</td>\n",
       "      <td>1K3</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>it works as expected. I should have sprung for...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>nothing to really say....</td>\n",
       "      <td>1356220800</td>\n",
       "      <td>2012-12-23</td>\n",
       "      <td>715</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3H99DFEG68SR</td>\n",
       "      <td>B007WTAJTO</td>\n",
       "      <td>1m2</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This think has worked out great.Had a diff. br...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Great buy at this price!!!  *** UPDATE</td>\n",
       "      <td>1384992000</td>\n",
       "      <td>2013-11-21</td>\n",
       "      <td>382</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A375ZM4U047O79</td>\n",
       "      <td>B007WTAJTO</td>\n",
       "      <td>2&amp;amp;1/2Men</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Bought it with Retail Packaging, arrived legit...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>best deal around</td>\n",
       "      <td>1373673600</td>\n",
       "      <td>2013-07-13</td>\n",
       "      <td>513</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  reviewerName helpful  \\\n",
       "0  A3SBTW3WS4IQSN  B007WTAJTO           NaN  [0, 0]   \n",
       "1  A18K1ODH1I2MVB  B007WTAJTO          0mie  [0, 0]   \n",
       "2  A2FII3I2MBMUIA  B007WTAJTO           1K3  [0, 0]   \n",
       "3   A3H99DFEG68SR  B007WTAJTO           1m2  [0, 0]   \n",
       "4  A375ZM4U047O79  B007WTAJTO  2&amp;1/2Men  [0, 0]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0                                         No issues.      4.0   \n",
       "1  Purchased this for my device, it worked as adv...      5.0   \n",
       "2  it works as expected. I should have sprung for...      4.0   \n",
       "3  This think has worked out great.Had a diff. br...      5.0   \n",
       "4  Bought it with Retail Packaging, arrived legit...      5.0   \n",
       "\n",
       "                                  summary  unixReviewTime  reviewTime  \\\n",
       "0                              Four Stars      1406073600  2014-07-23   \n",
       "1                           MOAR SPACE!!!      1382659200  2013-10-25   \n",
       "2               nothing to really say....      1356220800  2012-12-23   \n",
       "3  Great buy at this price!!!  *** UPDATE      1384992000  2013-11-21   \n",
       "4                        best deal around      1373673600  2013-07-13   \n",
       "\n",
       "   day_diff  helpful_yes  total_vote sentiment  \n",
       "0       138            0           0  Positive  \n",
       "1       409            0           0  Positive  \n",
       "2       715            0           0  Positive  \n",
       "3       382            0           0  Positive  \n",
       "4       513            0           0  Positive  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"./data/reviews_aws/amazon_review.csv\"\n",
    "try:\n",
    "    data = pd.read_csv(file_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {file_path}\")\n",
    "    exit()\n",
    "\n",
    "# Verify that the 'overall' column exists and is numeric\n",
    "if 'overall' not in data.columns:\n",
    "    print(\"Error: 'overall' column is missing in the dataset.\")\n",
    "    exit()\n",
    "if not pd.api.types.is_numeric_dtype(data['overall']):\n",
    "    print(\"Error: 'overall' column must contain numeric data.\")\n",
    "    exit()\n",
    "\n",
    "# Function to label sentiment\n",
    "def label_sentiment(overall):\n",
    "    if overall >= 4:\n",
    "        return \"Positive\"\n",
    "    elif overall == 3:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Negative\"\n",
    "\n",
    "# Add sentiment labels\n",
    "data['sentiment'] = data['overall'].apply(label_sentiment)\n",
    "\n",
    "# Save the updated file\n",
    "output_path = \"./data/reviews_aws/amazon_review_labeled.csv\"\n",
    "data.to_csv(output_path, index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(f\"Labeled file saved at: {output_path}\")\n",
    "data.head()  # Display the first few rows of the updated dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Preprocessing\n",
    "\n",
    "- Perform necessary text preprocessing steps such as tokenization, stop-word removal,\n",
    "stemming/lemmatization, and lowercasing. (10)\n",
    "- Remove any irrelevant columns, handle missing values, and clean text data by removing\n",
    "special characters, stopwords, and performing stemming/lemmatization.\n",
    "- Handle specific challenges of used text like hashtags, emojis, and slang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/marieth/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/marieth/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/marieth/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/marieth/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>day_diff</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>total_vote</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>processed_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3SBTW3WS4IQSN</td>\n",
       "      <td>B007WTAJTO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>No issues.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>1406073600</td>\n",
       "      <td>2014-07-23</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A18K1ODH1I2MVB</td>\n",
       "      <td>B007WTAJTO</td>\n",
       "      <td>0mie</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Purchased this for my device, it worked as adv...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>MOAR SPACE!!!</td>\n",
       "      <td>1382659200</td>\n",
       "      <td>2013-10-25</td>\n",
       "      <td>409</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>purchased device worked advertised never much ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2FII3I2MBMUIA</td>\n",
       "      <td>B007WTAJTO</td>\n",
       "      <td>1K3</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>it works as expected. I should have sprung for...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>nothing to really say....</td>\n",
       "      <td>1356220800</td>\n",
       "      <td>2012-12-23</td>\n",
       "      <td>715</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>work expected sprung higher capacity think mad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3H99DFEG68SR</td>\n",
       "      <td>B007WTAJTO</td>\n",
       "      <td>1m2</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This think has worked out great.Had a diff. br...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Great buy at this price!!!  *** UPDATE</td>\n",
       "      <td>1384992000</td>\n",
       "      <td>2013-11-21</td>\n",
       "      <td>382</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>think worked greathad diff bran 64gb card went...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A375ZM4U047O79</td>\n",
       "      <td>B007WTAJTO</td>\n",
       "      <td>2&amp;amp;1/2Men</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Bought it with Retail Packaging, arrived legit...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>best deal around</td>\n",
       "      <td>1373673600</td>\n",
       "      <td>2013-07-13</td>\n",
       "      <td>513</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>bought retail packaging arrived legit orange e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  reviewerName helpful  \\\n",
       "0  A3SBTW3WS4IQSN  B007WTAJTO           NaN  [0, 0]   \n",
       "1  A18K1ODH1I2MVB  B007WTAJTO          0mie  [0, 0]   \n",
       "2  A2FII3I2MBMUIA  B007WTAJTO           1K3  [0, 0]   \n",
       "3   A3H99DFEG68SR  B007WTAJTO           1m2  [0, 0]   \n",
       "4  A375ZM4U047O79  B007WTAJTO  2&amp;1/2Men  [0, 0]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0                                         No issues.      4.0   \n",
       "1  Purchased this for my device, it worked as adv...      5.0   \n",
       "2  it works as expected. I should have sprung for...      4.0   \n",
       "3  This think has worked out great.Had a diff. br...      5.0   \n",
       "4  Bought it with Retail Packaging, arrived legit...      5.0   \n",
       "\n",
       "                                  summary  unixReviewTime  reviewTime  \\\n",
       "0                              Four Stars      1406073600  2014-07-23   \n",
       "1                           MOAR SPACE!!!      1382659200  2013-10-25   \n",
       "2               nothing to really say....      1356220800  2012-12-23   \n",
       "3  Great buy at this price!!!  *** UPDATE      1384992000  2013-11-21   \n",
       "4                        best deal around      1373673600  2013-07-13   \n",
       "\n",
       "   day_diff  helpful_yes  total_vote sentiment  \\\n",
       "0       138            0           0  Positive   \n",
       "1       409            0           0  Positive   \n",
       "2       715            0           0  Positive   \n",
       "3       382            0           0  Positive   \n",
       "4       513            0           0  Positive   \n",
       "\n",
       "                                    processed_review  \n",
       "0                                              issue  \n",
       "1  purchased device worked advertised never much ...  \n",
       "2  work expected sprung higher capacity think mad...  \n",
       "3  think worked greathad diff bran 64gb card went...  \n",
       "4  bought retail packaging arrived legit orange e...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):  # Check if the value is not a string\n",
    "        return \"\"  # Return an empty string or handle it as needed\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords and lemmatize\n",
    "    processed_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    # Join tokens back into a single string\n",
    "    return ' '.join(processed_tokens)\n",
    "\n",
    "# Fill NaN values in the 'reviewText' column\n",
    "data['reviewText'] = data['reviewText'].fillna(\"\")\n",
    "\n",
    "# Apply the preprocessing function\n",
    "data['processed_review'] = data['reviewText'].apply(preprocess_text)\n",
    "\n",
    "# Check the first few rows\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant columns\n",
    "irrelevant_columns = ['reviewerID', 'asin', 'reviewerName', 'helpful', 'unixReviewTime', \n",
    "                      'reviewTime', 'day_diff', 'summary', 'helpful_yes', 'total_vote']\n",
    "data = data.drop(columns=irrelevant_columns, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "processed_review    0\n",
      "overall             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count missing values in specific columns\n",
    "missing_values = data[['processed_review', 'overall']].isnull().sum()\n",
    "\n",
    "# Display the result\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>processed_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No issues.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Purchased this for my device, it worked as adv...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>purchased device worked advertised never much ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it works as expected. I should have sprung for...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>work expected sprung higher capacity think mad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This think has worked out great.Had a diff. br...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>think worked greathad diff bran 64gb card went...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bought it with Retail Packaging, arrived legit...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>bought retail packaging arrived legit orange e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall sentiment  \\\n",
       "0                                         No issues.      4.0  Positive   \n",
       "1  Purchased this for my device, it worked as adv...      5.0  Positive   \n",
       "2  it works as expected. I should have sprung for...      4.0  Positive   \n",
       "3  This think has worked out great.Had a diff. br...      5.0  Positive   \n",
       "4  Bought it with Retail Packaging, arrived legit...      5.0  Positive   \n",
       "\n",
       "                                    processed_review  \n",
       "0                                              issue  \n",
       "1  purchased device worked advertised never much ...  \n",
       "2  work expected sprung higher capacity think mad...  \n",
       "3  think worked greathad diff bran 64gb card went...  \n",
       "4  bought retail packaging arrived legit orange e...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill missing values\n",
    "data['reviewText'] = data['reviewText'].fillna(\"\")  # Replace NaN in 'reviewText'\n",
    "data['overall'] = data['overall'].fillna(data['overall'].median())  # Replace NaN in 'overall'\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "processed_review    0\n",
      "overall             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count missing values in specific columns\n",
    "missing_values = data[['processed_review', 'overall']].isnull().sum()\n",
    "\n",
    "# Display the result\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Initialize stopwords and stemmer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):  # Handle non-string values\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords and apply stemming\n",
    "    processed_tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Join tokens back into a single string\n",
    "    return ' '.join(processed_tokens)\n",
    "\n",
    "# Apply text preprocessing to 'reviewText'\n",
    "data['processed_review'] = data['reviewText'].apply(preprocess_text)\n",
    "####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviewText          0\n",
      "overall             0\n",
      "sentiment           0\n",
      "processed_review    0\n",
      "dtype: int64\n",
      "                                       processed_review  overall sentiment\n",
      "2     work expect sprung higher capac think made bit...      4.0  Positive\n",
      "2732  work advert load fast problem pull adapt load ...      4.0  Positive\n",
      "4733  product arriv time expect work exactli adverti...      5.0  Positive\n",
      "2315  ill never need anotherbigg memori card fast pl...      4.0  Positive\n",
      "1869  els say sandisk memori card use almost exclus ...      5.0  Positive\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Sample cleaned data\n",
    "print(data[['processed_review', 'overall', 'sentiment']].sample(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordsegment import load, segment\n",
    "\n",
    "# Load wordsegment model\n",
    "load()\n",
    "\n",
    "def handle_hashtags(text):\n",
    "    # Identify hashtags\n",
    "    hashtags = re.findall(r\"#\\w+\", text)\n",
    "    for hashtag in hashtags:\n",
    "        # Split hashtag into words\n",
    "        words = \" \".join(segment(hashtag[1:]))  # Remove '#' and segment\n",
    "        text = text.replace(hashtag, words)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "def handle_emojis(text):\n",
    "    # Replace emojis with their descriptions (e.g., 😊 -> \":smiling_face_with_smiling_eyes:\")\n",
    "    text = emoji.demojize(text, delimiters=(\" \", \" \"))\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example slang dictionary\n",
    "slang_dict = {\n",
    "    \"u\": \"you\",\n",
    "    \"ur\": \"your\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"idk\": \"I don't know\",\n",
    "}\n",
    "\n",
    "def handle_slang(text):\n",
    "    # Replace slang words with their standard equivalents\n",
    "    words = text.split()\n",
    "    replaced_words = [slang_dict.get(word.lower(), word) for word in words]\n",
    "    return \" \".join(replaced_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                              reviewText  overall sentiment  \\\n",
      "0                                            No issues.      4.0  Positive   \n",
      "1     Purchased this for my device, it worked as adv...      5.0  Positive   \n",
      "2     it works as expected. I should have sprung for...      4.0  Positive   \n",
      "3     This think has worked out great.Had a diff. br...      5.0  Positive   \n",
      "4     Bought it with Retail Packaging, arrived legit...      5.0  Positive   \n",
      "...                                                 ...      ...       ...   \n",
      "4910  I bought this Sandisk 16GB Class 10 to use wit...      1.0  Negative   \n",
      "4911  Used this for extending the capabilities of my...      5.0  Positive   \n",
      "4912  Great card that is very fast and reliable. It ...      5.0  Positive   \n",
      "4913  Good amount of space for the stuff I want to d...      5.0  Positive   \n",
      "4914  I've heard bad things about this 64gb Micro SD...      5.0  Positive   \n",
      "\n",
      "                                       processed_review  \n",
      "0                                                  issu  \n",
      "1     purchas devic work advertis never much phone m...  \n",
      "2     work expect sprung higher capac think made bit...  \n",
      "3     think work greathad diff bran gb card went sou...  \n",
      "4     bought retail packag arriv legit orang envelop...  \n",
      "...                                                 ...  \n",
      "4910  bought sandisk gb class use htc inspir month g...  \n",
      "4911  use extend capabl samsung galaxi note greatli ...  \n",
      "4912  great card fast reliabl come option adapt sd s...  \n",
      "4913         good amount space stuff want fit gopro say  \n",
      "4914  ive heard bad thing gb micro sd card crap week...  \n",
      "\n",
      "[4915 rows x 4 columns]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>processed_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No issues.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>issu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Purchased this for my device, it worked as adv...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>purchas devic work advertis never much phone m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it works as expected. I should have sprung for...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>work expect sprung higher capac think made bit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This think has worked out great.Had a diff. br...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>think work greathad diff bran gb card went sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bought it with Retail Packaging, arrived legit...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>bought retail packag arriv legit orang envelop...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall sentiment  \\\n",
       "0                                         No issues.      4.0  Positive   \n",
       "1  Purchased this for my device, it worked as adv...      5.0  Positive   \n",
       "2  it works as expected. I should have sprung for...      4.0  Positive   \n",
       "3  This think has worked out great.Had a diff. br...      5.0  Positive   \n",
       "4  Bought it with Retail Packaging, arrived legit...      5.0  Positive   \n",
       "\n",
       "                                    processed_review  \n",
       "0                                               issu  \n",
       "1  purchas devic work advertis never much phone m...  \n",
       "2  work expect sprung higher capac think made bit...  \n",
       "3  think work greathad diff bran gb card went sou...  \n",
       "4  bought retail packag arriv legit orang envelop...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_text_with_challenges(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Handle hashtags\n",
    "    text = handle_hashtags(text)\n",
    "    \n",
    "    \n",
    "    # Handle emojis\n",
    "    text = handle_emojis(text)\n",
    "    \n",
    "    # Handle slang\n",
    "    text = handle_slang(text)\n",
    "    \n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords and apply stemming\n",
    "    processed_tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Join tokens back into a single string\n",
    "    return \" \".join(processed_tokens)\n",
    "\n",
    "# Apply the combined preprocessing to 'reviewText'\n",
    "print(data.head)\n",
    "data['processed_review'] = data['reviewText'].apply(preprocess_text_with_challenges)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          reviewText  \\\n",
      "0                                         No issues.   \n",
      "1  Purchased this for my device, it worked as adv...   \n",
      "2  it works as expected. I should have sprung for...   \n",
      "3  This think has worked out great.Had a diff. br...   \n",
      "4  Bought it with Retail Packaging, arrived legit...   \n",
      "\n",
      "                                    processed_review  \n",
      "0                                               issu  \n",
      "1  purchas devic work advertis never much phone m...  \n",
      "2  work expect sprung higher capac think made bit...  \n",
      "3  think work greathad diff bran gb card went sou...  \n",
      "4  bought retail packag arriv legit orang envelop...  \n",
      "Processed data saved at: ./data/reviews_aws/amazon_review_preprocessed.csv\n"
     ]
    }
   ],
   "source": [
    "# Display some processed examples\n",
    "print(data[['reviewText', 'processed_review']].head())\n",
    "\n",
    "# Save the updated dataset\n",
    "output_path = \"./data/reviews_aws/amazon_review_preprocessed.csv\"\n",
    "data.to_csv(output_path, index=False)\n",
    "print(f\"Processed data saved at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature Extraction and Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explore different feature representation methods such as bag-of-words, TF-IDF, word\n",
    "embeddings (e.g., Word2Vec or GloVe), or contextual embeddings (e.g., BERT or GPT).\n",
    "Experiment with 3 different feature extraction techniques to capture meaningful\n",
    "representations of social media text where the 3 techniques should be of different\n",
    "word embedding categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. TF-IDF Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust max_features\n",
    "\n",
    "# Fit and transform the 'processed_review' column\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(data['processed_review'].fillna('')).toarray()\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "import pandas as pd\n",
    "tfidf_df = pd.DataFrame(tfidf_features, columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Add TF-IDF features to the original dataset (optional)\n",
    "data = pd.concat([data.reset_index(drop=True), tfidf_df.reset_index(drop=True)], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Word2Vec Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Prepare tokenized sentences\n",
    "#test \n",
    "tokenized_sentences = data['processed_review'].fillna('').apply(lambda x: x.split())\n",
    "\n",
    "# Train a Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=2, workers=4)\n",
    "\n",
    "# Generate sentence embeddings by averaging word vectors\n",
    "def get_sentence_embedding(sentence):\n",
    "    vectors = [word2vec_model.wv[word] for word in sentence if word in word2vec_model.wv]\n",
    "    if len(vectors) > 0:\n",
    "        return sum(vectors) / len(vectors)\n",
    "    else:\n",
    "        return [0] * 100  # Vector size\n",
    "\n",
    "data['word2vec_embedding'] = tokenized_sentences.apply(get_sentence_embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. BERT Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, BertModel\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load pre-trained BERT tokenizer and model\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to get BERT embeddings\n",
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True, padding='max_length')\n",
    "    outputs = model(**inputs)\n",
    "    # Use the CLS token embedding (first token) as the sentence representation\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().detach().numpy()\n",
    "    return cls_embedding\n",
    "\n",
    "# Apply BERT embedding to each review\n",
    "data['bert_embedding'] = data['processed_review'].fillna('').apply(get_bert_embedding)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
