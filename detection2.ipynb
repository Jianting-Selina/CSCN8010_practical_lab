{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456 images have been renamed in the folder ./data/strawberry/healthy.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def rename_images_in_folder(folder, prefix):\n",
    "    \"\"\"\n",
    "    Renames all images in a specified folder with a given prefix.\n",
    "\n",
    "    Args:\n",
    "        folder (str): Path to the folder containing the images.\n",
    "        prefix (str): Prefix for the new image names.\n",
    "    \"\"\"\n",
    "    # Get a list of files in the folder\n",
    "    files = os.listdir(folder)\n",
    "\n",
    "    # Filter only files with common image extensions\n",
    "    valid_extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\"}\n",
    "    images = [file for file in files if os.path.splitext(file)[1].lower() in valid_extensions]\n",
    "\n",
    "    # Step 1: Add a temporary prefix to avoid conflicts\n",
    "    temp_prefix = \"temp_\"\n",
    "    for index, image in enumerate(images):\n",
    "        extension = os.path.splitext(image)[1]\n",
    "        current_path = os.path.join(folder, image)\n",
    "        temp_name = f\"{temp_prefix}{index}{extension}\"\n",
    "        temp_path = os.path.join(folder, temp_name)\n",
    "        os.rename(current_path, temp_path)\n",
    "\n",
    "    # Step 2: Rename files with the desired prefix\n",
    "    temp_files = os.listdir(folder)  # Reload the updated file list\n",
    "    temp_images = [file for file in temp_files if file.startswith(temp_prefix)]\n",
    "    for index, temp_image in enumerate(temp_images, start=1):\n",
    "        extension = os.path.splitext(temp_image)[1]\n",
    "        temp_path = os.path.join(folder, temp_image)\n",
    "        new_name = f\"{prefix}{index}{extension}\"\n",
    "        new_path = os.path.join(folder, new_name)\n",
    "        os.rename(temp_path, new_path)\n",
    "\n",
    "    print(f\"{len(images)} images have been renamed in the folder {folder}.\")\n",
    "\n",
    "# Usage examples\n",
    "#rename_images_in_folder(\"./data/strawberry/healthy\", \"strawberry_healthy_\")\n",
    "#rename_images_in_folder(\"./data/strawberry/Leaf_scorch\", \"strawberry_leaf_scorch_\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "\n",
    "# Directory paths\n",
    "original_dir = pathlib.Path(\"./data/strawberry/alldata\")\n",
    "new_base_dir = pathlib.Path(\"./data/strawberry/strawberry_healthy_diseased_alldata_small\")\n",
    "\n",
    "# Function to create subsets\n",
    "def make_subset(category, subset_name, start_index, end_index):\n",
    "    \"\"\"\n",
    "    Creates a subset of images for a specific category.\n",
    "\n",
    "    Args:\n",
    "        category (str): Category ('strawberry_healthy' or 'strawberry_leaf_scorch').\n",
    "        subset_name (str): Subset ('train', 'validation', 'test').\n",
    "        start_index (int): Starting index of the images to copy.\n",
    "        end_index (int): Ending index of the images to copy.\n",
    "    \"\"\"\n",
    "    # Create the destination directory\n",
    "    dir = new_base_dir / subset_name / category\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "    # Generate file names and copy files\n",
    "    fnames = [f\"{category}_{i}.JPG\" for i in range(start_index, end_index + 1)]\n",
    "    for fname in fnames:\n",
    "        src = original_dir / fname\n",
    "        dst = dir / fname\n",
    "        if src.exists():  # Check if the file exists before copying\n",
    "            shutil.copyfile(src, dst)\n",
    "\n",
    "# Create subsets for each category\n",
    "# Healthy\n",
    "make_subset(\"strawberry_healthy\", \"train\", start_index=1, end_index=182)\n",
    "make_subset(\"strawberry_healthy\", \"validation\", start_index=183, end_index=274)\n",
    "make_subset(\"strawberry_healthy\", \"test\", start_index=274, end_index=456)\n",
    "\n",
    "# Diseased\n",
    "make_subset(\"strawberry_leaf_scorch\", \"train\", start_index=1, end_index=442)\n",
    "make_subset(\"strawberry_leaf_scorch\", \"validation\", start_index=443, end_index=663)\n",
    "make_subset(\"strawberry_leaf_scorch\", \"test\", start_index=664, end_index=1109)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 files belonging to 2 classes.\n",
      "Found 313 files belonging to 2 classes.\n",
      "Found 629 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "data_folder = pathlib.Path('./data/strawberry/strawberry_healthy_diseased_alldata_small')\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    data_folder / \"train\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    data_folder / \"validation\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    data_folder / \"test\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 18:34:00.856147: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [624]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2024-12-07 18:34:00.857167: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [624]\n",
      "\t [[{{node Placeholder/_4}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - ETA: 0s - loss: 0.7200 - accuracy: 0.6827"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 18:34:24.861330: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [313]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2024-12-07 18:34:24.862134: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [313]\n",
      "\t [[{{node Placeholder/_4}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 28s 1s/step - loss: 0.7200 - accuracy: 0.6827 - val_loss: 0.5325 - val_accuracy: 0.7061\n",
      "Epoch 2/30\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.5501 - accuracy: 0.7099 - val_loss: 0.3062 - val_accuracy: 0.9553\n",
      "Epoch 3/30\n",
      "20/20 [==============================] - 24s 1s/step - loss: 0.4958 - accuracy: 0.8365 - val_loss: 0.1855 - val_accuracy: 0.9297\n",
      "Epoch 4/30\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.2147 - accuracy: 0.9119 - val_loss: 0.0626 - val_accuracy: 0.9808\n",
      "Epoch 5/30\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.1871 - accuracy: 0.9247 - val_loss: 0.0555 - val_accuracy: 0.9872\n",
      "Epoch 6/30\n",
      "20/20 [==============================] - 26s 1s/step - loss: 0.0538 - accuracy: 0.9840 - val_loss: 0.0171 - val_accuracy: 0.9904\n",
      "Epoch 7/30\n",
      " 4/20 [=====>........................] - ETA: 20s - loss: 0.0464 - accuracy: 0.9844"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"./models/convnet_from_scratch_1207.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\")\n",
    "]\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=30,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = keras.models.load_model(\"./models/convnet_from_scratch_1207.keras\")\n",
    "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
